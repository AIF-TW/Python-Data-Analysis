{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference: https://www.kaggle.com/startupsci/titanic-data-science-solutions/notebook\n",
    "'''\n",
    "pclass: A proxy for socio-economic status (SES)\n",
    "1st = Upper\n",
    "2nd = Middle\n",
    "3rd = Lower\n",
    "\n",
    "age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "sibsp: The dataset defines family relations in this way...\n",
    "Sibling = brother, sister, stepbrother, stepsister\n",
    "Spouse = husband, wife (mistresses and fiancÃ©s were ignored)\n",
    "\n",
    "parch: The dataset defines family relations in this way...\n",
    "Parent = mother, father\n",
    "Child = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore parch=0 for them.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire data\n",
    "train_df = pd.read_csv('../common/dataset/titanic/train.csv')\n",
    "test_df = pd.read_csv('../common/dataset/titanic/test.csv')\n",
    "combine = [train_df, test_df]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()\n",
    "# Cabin > Age > Embarked features contain a number of null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df.head()\n",
    "test_df.info()\n",
    "# Cabin > Age are incomplete in case of test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print column names\n",
    "print(train_df.columns) \n",
    "\n",
    "# preview the data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe the numerical data\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe the categorical data\n",
    "train_df.describe(include=['O'])  # string stype data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm some of our observations and assumptions, we can quickly analyze our feature correlations by pivoting features against each other. We can only do so at this stage for features which do not have any empty values. It also makes sense doing so only for features which are categorical (Sex), ordinal (Pclass) or discrete (SibSp, Parch) type.\n",
    "\n",
    "Pclass We observe significant correlation (>0.5) among Pclass=1 and Survived. We decide to include this feature in our model.\n",
    "\n",
    "Sex We confirm the observation during problem definition that Sex=female had very high survival rate at 74%.\n",
    "\n",
    "SibSp and Parch These features have zero correlation for certain values. It may be best to derive a feature or a set of features from these individual features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[[\"Pclass\", \"Survived\"]].groupby(['Pclass'], as_index=False).mean().sort_values(by=\"Survived\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by=\"Survived\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['SibSp', \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by=\"Survived\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by=\"Survived\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby(['Parch'], as_index=False).agg({'Survived':'mean', \"Sex\": 'count'}).sort_values(by = \"Survived\", ascending = False)\n",
    "\n",
    "# train_df[\"Parch\"] == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A histogram chart is useful for analyzing continous numerical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlating numerical features\n",
    "Let us start by understanding correlations between numerical features and our solution goal (Survived).\n",
    "\n",
    "A histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have better survival rate?)\n",
    "\n",
    "### Observations.\n",
    "\n",
    "Infants (Age <=4) had high survival rate.\n",
    "\n",
    "Oldest passengers (Age = 80) survived.\n",
    "\n",
    "Large number of 15-25 year olds did not survive.\n",
    "\n",
    "Most passengers are in 15-35 age range.\n",
    "\n",
    "### Decisions.\n",
    "\n",
    "This simple analysis confirms our assumptions as decisions for subsequent workflow stages.\n",
    "\n",
    "We should consider Age in our model training.\n",
    "\n",
    "Complete the Age feature for null values.\n",
    "\n",
    "We should band age groups ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "axes1 = plt.subplot(1, 2, 1)\n",
    "axes1.hist(train_df.Age[train_df.Survived == 0].dropna(), bins=20)\n",
    "axes1.set_title(\"survived = 0\")\n",
    "\n",
    "axes2 = plt.subplot(1, 2, 2)\n",
    "axes2.set_ylim(0, 50)\n",
    "axes2.set_title(\"survived = 1\")\n",
    "axes2.hist(train_df.Age[train_df.Survived == 1].dropna(), bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlating numerical and ordinal features\n",
    "\n",
    "We can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\n",
    "\n",
    "### Observations.\n",
    "\n",
    "Pclass=3 had most passengers, however most did not survive.\n",
    "\n",
    "Confirms our classifying assumption .\n",
    "\n",
    "Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption .\n",
    "\n",
    "Most passengers in Pclass=1 survived. Confirms our classifying assumption.\n",
    "\n",
    "Pclass varies in terms of Age distribution of passengers.\n",
    "\n",
    "### Decisions.\n",
    "\n",
    "Consider Pclass for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "survived = [0, 1]\n",
    "pclass = [1, 2, 3]\n",
    "tuples = [(y, x) for x in pclass for y in survived]\n",
    "print(tuples)\n",
    "\n",
    "for i, value in enumerate(tuples):\n",
    "    survived, pclass = value[0], value[1]\n",
    "    axes = plt.subplot(3, 2, i+1)\n",
    "    axes.hist(train_df.Age[np.logical_and(train_df.Survived == survived, train_df.Pclass == pclass)].dropna(), bins=20)\n",
    "    axes.set_title(f\"survived = {survived} |pclass = {pclass}\")\n",
    "    axes.set_ylim(0, 40)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlating categorical features\n",
    "Now we can correlate categorical features with our solution goal.\n",
    "\n",
    "### Observations.\n",
    "\n",
    "Female passengers had much better survival rate than males. Confirms classifying.\n",
    "    \n",
    "Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass \n",
    "and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\n",
    "    \n",
    "Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing.\n",
    "    \n",
    "Ports of embarkation have varying survival rates for Pclass=3 and among male passengers. Correlating.\n",
    "    \n",
    "### Decisions.\n",
    "\n",
    "Add Sex feature to model training.\n",
    "    \n",
    "Complete and add Embarked feature to model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 12))\n",
    "embarked = ['S', 'C', 'Q']\n",
    "\n",
    "for i, value in enumerate(embarked):\n",
    "    on = value[0]\n",
    "    axes = plt.subplot(3, 1, i+1)\n",
    "    train_df[np.logical_and(train_df[\"Embarked\"] == on, train_df[\"Sex\"] == \"male\")].groupby([\"Pclass\"]).mean()[\"Survived\"].plot()\n",
    "    train_df[np.logical_and(train_df[\"Embarked\"] == on, train_df[\"Sex\"] == \"female\")].groupby([\"Pclass\"]).mean()[\"Survived\"].plot()\n",
    "    axes.set_title(f\"Embarked = {on}\")\n",
    "    axes.set_xticks([1, 2, 3])\n",
    "    axes.legend([\"male\", \"female\"], fontsize=12, loc=\"upper right\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlating categorical and numerical features\n",
    "We may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\n",
    "\n",
    "### Observations.\n",
    "\n",
    "Higher fare paying passengers had better survival. Confirms our assumption for creating fare ranges.\n",
    "\n",
    "Port of embarkation correlates with survival rates. Confirms correlating and completing.\n",
    "    \n",
    "### Decisions.\n",
    "\n",
    "Consider banding Fare feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "survived = [0, 1]\n",
    "embarked = ['S', 'C', 'Q']\n",
    "tuples = [(y, x) for x in embarked for y in survived]\n",
    "print(tuples)\n",
    "\n",
    "for i, value in enumerate(tuples):\n",
    "    survived, embarked = value[0], value[1]\n",
    "    axes = plt.subplot(3, 2, i+1)\n",
    "    train_df[np.logical_and(train_df.Survived == survived, train_df.Embarked == embarked)].groupby([\"Sex\"])['Fare'].mean().plot(kind=\"bar\")\n",
    "    axes.set_title(f\"survived = {survived} |Embarked = {embarked}\")\n",
    "    axes.set_ylim(0, 80)\n",
    "    plt.xticks(rotation='horizontal')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want to drop the Cabin and Ticket features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)\n",
    "\n",
    "train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "test_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "print(\"After\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating new feature extracting from existing\n",
    "We want to analyze if Name feature can be engineered to extract titles and test correlation between titles and survival, before dropping Name and PassengerId features.\n",
    "\n",
    "In the following code we extract Title feature using regular expressions. The RegEx pattern (\\w+\\.) matches the first word which ends with a dot character within Name feature. The expand=False flag returns a DataFrame.\n",
    "\n",
    "### Observations.\n",
    "\n",
    "When we plot Title, Age, and Survived, we note the following observations.\n",
    "\n",
    "Most titles band Age groups accurately. For example: Master title has Age mean of 5 years.\n",
    "Survival among Title Age bands varies slightly.\n",
    "Certain titles mostly survived (Mme, Lady, Sir) or did not (Don, Rev, Jonkheer).\n",
    "### Decision.\n",
    "\n",
    "We decide to retain the new Title feature for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new feature extracting from existing\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "pd.crosstab(train_df['Title'], train_df['Sex'])  # from A to Z more than one + ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replace many titles with a more common name or classify them as Rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "train_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert the categorical titles to ordinal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also do not need the PassengerId feature in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\n",
    "test_df = test_df.drop(['Name'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting a categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Sex'] = dataset['Sex'].map({'female': 1, 'male': 0}).astype(int)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by preparing an empty array to contain guessed Age values based on Pclass x Gender combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_ages = np.zeros((2, 3))\n",
    "guess_ages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we iterate over Sex (0 or 1) and Pclass (1, 2, 3) to calculate guessed values of Age for the six combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            guess_df = dataset[(dataset['Sex'] == i) & (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
    "            age_guess = guess_df.median()\n",
    "            # convert random age float to nearest .5 age\n",
    "            guess_ages[i, j] = int(age_guess / 0.5 + 0.5) * 0.5\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            dataset.loc[(dataset.Age.isnull() & (dataset.Sex == i)) & (dataset.Pclass == j+1), 'Age'] = guess_ages[i, j]\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create Age bands and determine correlations with Survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['AgeBand'] = pd.cut(train_df['Age'], 5)  # cut into same width\n",
    "train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us replace Age with ordinals based on these bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset.loc[dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[dataset['Age'] > 64, 'Age'] = 4\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove the AgeBand feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['AgeBand'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a new feature for FamilySize which combines Parch and SibSp. This will enable us to drop Parch and SibSp from our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "train_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create another feature called IsAlone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "train_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us drop Parch, SibSp, and FamilySize features in favor of IsAlone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create an artificial feature combining Pclass and Age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n",
    "\n",
    "train_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completing a categorical feature\n",
    "Embarked feature takes S, Q, C values based on port of embarkation. Our training dataset has two missing values. We simply fill these with the most common occurance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_port = train_df.Embarked.dropna().mode()[0]\n",
    "freq_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n",
    "\n",
    "train_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting categorical feature to numeric\n",
    "We can now convert the EmbarkedFill feature by creating a new numeric Port feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick completing and converting a numeric feature\n",
    "We can now complete the Fare feature for single missing value in test dataset using mode to get the value that occurs most frequently for this feature. We do this in a single line of code.\n",
    "\n",
    "Note that we are not creating an intermediate new feature or doing any further analysis for correlation to guess missing feature as we are replacing only a single value. The completion goal achieves desired requirement for model algorithm to operate on non-null values.\n",
    "\n",
    "We may also want round off the fare to two decimals as it represents currency.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can not create FareBand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\n",
    "train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the Fare feature to ordinal values based on the FareBand.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare'] = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "train_df = train_df.drop(['FareBand'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ....to be continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}